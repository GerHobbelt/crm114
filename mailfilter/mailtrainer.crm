#! /usr/local/bin/crm114
# --(spam good repeat streak random worst verbose validate thick reload collapse report_header rfile goodcss spamcss config fileprefix)
#
# A TUNE-type mailtrainer; repeat is the maximum number of
# repeated executions.  This filter uses the same config as
# mailfilter.crm.  Good and spam are trained alternately until
# each file has been examined and possibly trained at least REPEAT
# times, or until a run of at least STREAK length has been correctly
# classified.  If RANDOM is set, then randomize the order of the
# files being trained on each pass.
#
# Worst means to rerun the entire set, and then retrain only the
# N worst errors.  In the limit, this is the single worst error.
# This is slow but yields very "tight" and accurate files.
#
# Copyright (C) 2002-2008 William S. Yerazunis; licensed under the
# GNU Public License (GPL) version 2.  A copy of this license is included
# in the distribution media, or obtain one from www.fsf.org .
#
# Note to SunOS and FreeBSD users - you MUST remove EVERYTHING on
# the first line of this program from the first "-" to the end of
# the first line (including the "-" sign itself) or you will not get
# what you expect.  This is due to "differences of opinion" on how
# a bangline should be dealt with.
#

window

{
    isolate (:a:) //
    isolate (:c:) /:*:_argc:/
    {
        eval (:a:) /:_arg:@::*:c:-1::/
        match [:*:a:] <absent> /^--help$/
        eval (:c:) /:@::*:c:-1:/
        eval /:@::*:c: >= 1:/
        liaf
    }
    match [:*:a:] /^--help$/
	
    output /This is CRM114's mailtrainer, which builds .css statistics\n/
    output /files.  It uses DSTTTR and mailfilter.cf configuration setup.\n/
    output /You *must* supply at least --good and --spam to run.\n/
    output /Command Format:\n/
    output /      .\/mailtrainer.crm [options]*\n/
    output /\n/
    output /Required options:\n/
    output / --spam=\/spam\/directory\/    (one msg per file)\n/
    output / --good=\/good\/directory\/    (one msg per file)\n/
    output /\n/
    output /Or you have to specify one of these instead:\n/
    output / --spamfile=file\n/
    output /              (Train file. When file is '-', load from stdin)\n/
    output / --goodfile=file\n/
    output /              (Train file. When file is '-', load from stdin)\n/
    output /\n/
    output /Optional options:\n/
    output / --spamcss=spam_statistics.css\n/
    output /              (Default: spam.css)\n/
    output / --goodcss=good_statistics.css\n/
    output /              (Default: nonspam.css)\n/
    output / --repeat=N   (limit how many passes, default 1)\n/
    output / --streak=N   (exit on N perfect, default 10000)\n/
    output / --random     (train in random order, default not)\n/
    output / --worst=N    (train only the N worst errors per pass. SLOW!)\n/
    output / --verbose    (tell me more.)\n/
    output / --validate=regex\n/
    output /              (Don't train any filename matching regex;\n/
    output /               instead, hold them back and make a final test\n/
    output /               pass with those hold-backs at the end.)\n/
    output / --thick=N.N  (TTT value; default 10.0 for OSB is good)\n/
    output / --reload     (if not randomizing, whenever one set of files\n/
    output /               is exhausted, reload it.  Default- don't.)\n/
    output / --collapse   (collapse intermediate reporting lines)\n/
    output / --report_header='string'\n/
    output /              (include string in the report header and show\n/
    output /               the report.)\n/
    output / --config=filename\n/
    output /              (Use filename as the .cf file. Default is mailfilter.cf)\n/
    output / --fileprefix=dir\n/
    output /              (Look in this dir for the .css, .cf and .txt files)\n/
    output /              (I.e. expect all files in "fileprefix")\n/
    output /\n/
    output /MailFilter.CF Override Commands:\n/
    output /   You can specify any mailfilter.cf entry as an option on the command\n/
    output /   line to override that option in the mailfilter.cf configuration\n/
    output /   file, e.g.\n/
    output /     --do_base64=yes\n/
    output /   See the mailfilter.cf file for all available entries.\n/
    exit /42/
}

isolate (:program_fault_exit_code:) /66/   # [i_a] in case mailfilter.cf cannot be loaded: make sure we don't get an error report cascade.
isolate (:our_exit_code:) /0/
call /:exec_mailtrainer:/ (:our_exit_code:)
exit /:our_exit_code:/

:exec_mailtrainer: (:our_exit_code:)
isolate <default> (:program_fault_exit_code:) /66/

#
# --->>>    Basic Design Philosophy ( do these IN ORDER ) - note
#               that this is different for the worst strategy.
#
# 1) get directory listing of the good directory
#
# 2) get directory listing of the bad directory
#
# 3) for repcount < repeat (N passes through entire set)
#    and cleanrun < streak (M tests without a single error)
#
#    3a) cleanrun++,
#        test one from good ; if less than thresh, learn good, cleanrun=0.
#
#    3b) cleanrun++,
#        test one from spam; if more than -thresh, learn spam, cleanrun=0
#
#    3c) repcount++
#
# 4) email results to spam results and out to stdout as well.
#
##############################################################
#
#
#    ---  uncomment this if you want to include a "forced"
#         configuration file  ---
# insert mailfilterconfig.crm
#
#
#    --- These vars must have a value, or else we'll get errors ----
#

# GerH vs VANILLA fixes:
isolate (:_hosttype:) <default> /UNKNOWN/
# GerH vs VANILLA fixes -- END --

#
isolate <default> (:fileprefix:) //
#
isolate <default> (:do_refute_training:) /SET/

isolate (:classifier_reason:) /no reason yet/
#
isolate (:stats:) / pR: 0.000000 /
#
isolate (:pr:) /0.00000/
#
isolate <default> (:subj_text:) / (None) /
#
isolate <default> (:add_extra_stuff:) //
#
#      Isolate these email addresses, and give them values,
#      in case the user doesn't.
isolate <default> (:reject_address:) //
isolate <default> (:unsure_address:) //
isolate <default> (:fail_priority_mail_to:) //
isolate <default> (:fail_classify_mail_to:) //
isolate <default> (:fail_blacklist_mail_to:) //
isolate <default> (:fail_SSM_mail_to:)  //

#
#       now, :clf: is the classify & learn flags.
isolate <default> (:clf:) //

isolate (:dospath:) //
#

#####################################################################
#
#       This is the code to read the per-user configuration.  Note
#       that because this happens during the run, it will _override_
#       any command line arguments that get set.

isolate <default> (:verbose_startup:) //
isolate <default> (:config:) /:*:fileprefix:mailfilter.cf/

#
# read in the options/configuration file
#
call /:load_cf_file:/ [:*:config:]

#
# make sure verbose_logfile has a valid, non-empty value, so output is NOT logged to stdout
# unless we explicitly say so.
#
{
    eval /:@: :#:verbose_logfile: <= 2 :/    # a valid filename? assume at least 2 chars
    alter (:verbose_logfile:) /stderr/
}


###########################################################
#    Set up defaults for mail training...
#
isolate <default> (:spam:)  /ERROR!!!/
isolate <default> (:good:)  /ERROR!!!/
isolate <default> (:spamfile:) //
isolate <default> (:goodfile:) //
isolate <default> (:repeat:)   /1/
isolate <default> (:streak:)   /10000/
isolate <default> (:random:)   /no/
isolate <default> (:worst:)    /no/
isolate <default> (:verbose:)  /no/
isolate <default> (:validate:) //    # note that this is a bit tricky
isolate <default> (:reload:)   /no/
isolate <default> (:collapse:) //
isolate <default> (:report_header:) //
isolate <default> (:rfile:)    //
isolate (:spamcss:) <default> /spam.css/
isolate (:goodcss:) <default> /nonspam.css/
isolate (:force:) <default> //
isolate (:decision_length:) <default> /8192/

##### if --thick is specified, it overrides the :thick_threshold from *.cf
isolate <default> (:thick:)    /no/
{
    match <absent> [:thick:] /^no$/
    alter (:thick_threshold:) /:*:thick:/
}

call /:mk_abspath_on_fileprefix:/ [:*:goodcss:] (:goodcss:)
call /:mk_abspath_on_fileprefix:/ [:*:spamcss:] (:spamcss:)

#   and set up our bookkeeping variables
#
isolate (:throughall:) /0/
isolate (:cleanrun:) /0/
isolate (:spamfiles:) //
isolate (:goodfiles:) //
isolate (:filename:) //
isolate (:lfilename:) //
isolate (:worst_results:) //
isolate (:worst_retrains:) //
isolate (:z:) //
isolate (:dospath:) //

isolate (:exp_text: :a: :b: :c: :h:)

isolate (:m_text: :b_text: :i_text: :comment: :commentbin: :rewrites:)
isolate (:goodwildcard:)  //
isolate (:spamwildcard:)  //


#######################################################################
#
#    Do a quick check - has the password been changed or not?  If it's
#    still the default, put in something that will be well-nigh unguessable
#    (esp. since it will contain received headers that the sender cannot
#    see nor control.)
{
    match [:spw:] /DEFAULT-PASSWORD/
    # yes, it's the same as default.  So we scramble it just so
    # nobody can hack in without major trickery.
    hash (:spw:) /:*:_env_string::*:_dw:/

    call /:verbosity:/ [The password has not been changed; assigning randomized pass]
}

######################################################################
#
#     Set up the addresses that we might need to mail to
#
#     if a particular "fail" category hasn't been assigned, but
#     the :general_fails_to: category has, then send there instead
#
isolate (:reject_address:) /:*:general_fails_to:/
{
    match [:fail_priority_mail_to:] <absent> /[[:graph:]]/
    alter (:fail_priority_mail_to:) /:*:general_fails_to:/
}
{
    match [:fail_blacklist_mail_to:] <absent> /[[:graph:]]/
    alter (:fail_blacklist_mail_to:) /:*:general_fails_to:/
}
{
    match [:fail_SSM_mail_to:] <absent> /[[:graph:]]/
    alter (:fail_SSM_mail_to:) /:*:general_fails_to:/
}
{
    match [:fail_classify_mail_to:] <absent> /[[:graph:]]/
    alter (:fail_classify_mail_to:) /:*:general_fails_to:/
}

call /:verbosity:/ [Setting up the forwarding email addresses:\n\
  generic reject_address:  ':*:general_fails_to:'\n\
  fail_priority_mail_to:   ':*:general_fails_to:'\n\
  fail_blacklist_mail_to   ':*:general_fails_to:'\n\
  fail_SSM_mail_to:        ':*:general_fails_to:'\n\
  fail_classify_mail_to:   ':*:general_fails_to:'\n]



###########################################################
#
#       set gooddir and spamdir to the directory parts of the spec
#
isolate (:gooddir: :goodwildcard: :spamdir: :spamwildcard:) //
isolate (:single_file_mode:) //
{
	{
		match [:goodfile:] /./
		alter (:single_file_mode:) /SET/
		
		isolate (:ftype:) /G/
		{
			{
				# stdin? or regular file?
				match [:goodfile:] /^-?$/
				
				call /:verbosity:/ [Reading a single (GOOD) file from STDIN for training]
	
				input
			}
			alius
			{
				call /:verbosity:/ [Reading a single (GOOD) file from file ':*:goodfile:' for training]
	
				input [:*:goodfile: 0 :*:decision_length:]
			}
		}
		
		call /:mail_preprocess:/ [:_dw:] (:m_text:)
		#    output / M_TEXT: :*:m_text:\n/
		
		trap /.*/ (:reason:)
		{
			output / :*:reason:/
			output /Unable to process your good file ':*:goodfile:'\n/
			alter (:report:) /:*:report: Unable to process your good file ':*:goodfile:'\n/
			goto /:error_exit:/
		}
	}
	alius
	{
		match [:spamfile:] /./
		alter (:single_file_mode:) /SET/
		
		isolate (:ftype:) /S/
		{
			{
				# stdin? or regular file?
				match [:spamfile:] /^-*$/
	
				call /:verbosity:/ [Reading a single (BAD) file from STDIN for training]
	
				input
			}
			alius
			{
				call /:verbosity:/ [Reading a single (BAD) file from file ':*:spamfile:' for training]
	
				input [:*:spamfile: 0 :*:decision_length:]
			}
		}
		
		call /:mail_preprocess:/ [:_dw:] (:m_text:)
		#    output / M_TEXT: :*:m_text:\n/
		
		trap /.*/ (:reason:)
		{
			output / :*:reason:/
			output /Unable to process your spam file ':*:spamfile:'\n/
			alter (:report:) /:*:report: Unable to process your spam file ':*:spamfile:'\n/
			goto /:error_exit:/
		}
	}
	alius
	{
		match [:good:] (:: :gooddir: :goodwildcard:) /^(.*[\\\/])([^\\\/]*)$/
		match [:spam:] (:: :spamdir: :spamwildcard:) /^(.*[\\\/])([^\\\/]*)$/
		isolate (:goodwildcard:)
		isolate (:spamwildcard:)
		# make sure dir & path are set to something useful
		{
			match <absent> [:gooddir:] /./
			alter (:gooddir:) /./
		}
		{
			match <absent> [:spamdir:] /./
			alter (:spamdir:) /./
		}
		# make sure path has trailing slash
		{
			match <absent> [:gooddir:] /[\\\/]$/
			alter (:gooddir:) /:*:gooddir:\//
		}
		{
			match <absent> [:spamdir:] /[\\\/]$/
			alter (:spamdir:) /:*:spamdir:\//
		}
		# and ensure the wildcards at least match _something_: default = anything.
		{
			match <absent> [:goodwildcard:] /./
			{
				match [:_hosttype:] /Windows-MS/
				alter (:goodwildcard:) /*.*/
			}
			alius
			{
				alter (:goodwildcard:) /*/
			}
		}
		{
			match <absent> [:spamwildcard:] /./
			{
				match [:_hosttype:] /Windows-MS/
				alter (:spamwildcard:) /*.*/
			}
			alius
			{
				alter (:spamwildcard:) /*/
			}
		}

		call /:verbosity:/ [Directories and wildcard patterns:\n\
  spam directory: ':*:spamdir:', wildcard pattern: ':*:spamwildcard:'\n\
  good directory: ':*:gooddir:', wildcard pattern: ':*:goodwildcard:'\n]
	}
}



#############################################################\
#
#       Start our report:
#
isolate (:report:) /     MailTrainer Report  \n:*:report_header:\n\n/

#
alter (:report:) /:*:report:Commanded on:\n/
alter (:report:) /:*:report:  spam source directory: :*:spamdir::*:spamwildcard:\n/
alter (:report:) /:*:report:  good source directory: :*:gooddir::*:goodwildcard:\n/
{
	{
		match [:single_file_mode:] /SET/
		alter (:report:) /:*:report:  single file mode:      yes (type: :*:ftype:)\n/
	}
	alius
	{
		alter (:report:) /:*:report:  single file mode:      no\n/
	}
}
alter (:report:) /:*:report:  spam CSS file:         :*:spamcss:\n/
alter (:report:) /:*:report:  good CSS file:         :*:goodcss:\n/
alter (:report:) /:*:report:  classifier config:     :*:clf:\n/

#
# [i_a] make sure the training thick threshold is at least MAX(spam_threshold, good_threshold)
# so that a mailtrainer + post mailreaver classify cycle for any item which is TRAINED does
# NOT produce the counterintuitive 'don't know' result AFTER the training.
#
{
	isolate (:old_thick_threshold:) /:*:thick_threshold:/
	{
		eval /:@:0 - :*:spam_threshold: > :*:thick_threshold::/
		alter (:report:) /:*:report:  OVERRIDE thick threshold to at least reach SPAM threshold levels.\n/
		eval (:thick_threshold:) /:@:0 - :*:spam_threshold::/
	}
	{
		eval /:@::*:good_threshold: > :*:thick_threshold::/
		alter (:report:) /:*:report:  OVERRIDE thick threshold to at least reach GOOD threshold levels.\n/
		alter (:thick_threshold:) /:*:good_threshold:/
	}
}
alter (:report:) /:*:report:  threshold thickness:   :*:thick_threshold: <-- (S=:*:spam_threshold:, G=:*:good_threshold:, TTH=:*:old_thick_threshold:)\n/
alter (:report:) /:*:report:  max repetitions:       :*:repeat:\n/
alter (:report:) /:*:report:  stop when a streak of: :*:streak:\n/
alter (:report:) /:*:report:  randomization is:      :*:random:\n/
alter (:report:) /:*:report:  worst is:              :*:worst:\n/
alter (:report:) /:*:report:  verbose is:            :*:verbose:\n/
alter (:report:) /:*:report:  auto-reload:           :*:reload:\n/
alter (:report:) /:*:report:  concise log file:      :*:rfile:\n/




{
    {
        match [:validate:] /./
        alter (:report:) /:*:report:  validation regex:      :*:validate: \n/
    }
    alius
    {
        alter (:report:) /:*:report:  validation regex:      (none) \n/
        alter (:validate:) /[^\x00-\xFF]/    # this regex never matches.
    }
}

{
	{
		#  do we do an output report at the top?
		match [:collapse:] <absent> /SET/
		output /:*:report:/
	}
	alius
	{
		#  do we output the report header anyway
		match [:report_header:] /./
		output /:*:report:/
	}
	alius
	{
		call /:verbosity:/ [:*:report:]
	}
}

{
    # do we have an rfile?
    match [:rfile:] /./
    output <append> [:*:rfile:] /:*:report:/
}


############################################################
#
#       Get the good directory and the spam directory files
#
{
    match [:single_file_mode:] <absent> /SET/

    call /:verbosity:/ [Scanning SPAM directories to collect files for training\n]

    {
        call /:verbosity:/ [mailtrainer: host type = ':*:_hosttype:']
        match [:_hosttype:] /Windows-MS/
        call /:mk_dospath:/ [:*:spamdir::*:spamwildcard:] (:dospath:)
        call /:verbosity:/ [mailtrainer: scan dir: dir \/s \/b :*:dospath:]
        syscall /dir \/s \/b :*:dospath: / () (:spamfiles:)
        call /:verbosity:/ [directory scan for ':*:spamdir::*:spamwildcard:' --> ':*:dospath:' --> :*:spamfiles:\n]
    }
    alius
    {
        call /:verbosity:/ [mailtrainer: scan dir: find :*:spamdir: -type f -name ':*:spamwildcard:' -print]
        syscall /find :*:spamdir: -type f -name ':*:spamwildcard:' -print/ () (:spamfiles:)
        call /:verbosity:/ [directory scan for ':*:spamdir::*:spamwildcard:' --> :*:spamfiles:\n]
    }
    # output /spamfiles:  ':*:spamfiles:'\n/
    trap /.*/ (:reason:)
    {
        output /:*:reason:/
        output /Unable to process your spamdir at :*:spamdir: \n/
        alter (:report:) /:*:report: Unable to process your spamdir at :*:spamdir: \n/
        goto /:error_exit:/
    }
}

{
    match [:single_file_mode:] <absent> /SET/

    call /:verbosity:/ [Scanning GOOD directories to collect files for training\n]

    {
        call /:verbosity:/ [mailtrainer: host type = ':*:_hosttype:']
        match [:_hosttype:] /Windows-MS/
        call /:mk_dospath:/ [:*:gooddir::*:goodwildcard:] (:dospath:)
        call /:verbosity:/ [mailtrainer: scan dir: dir \/s \/b :*:dospath:]
        syscall /dir \/s \/b :*:dospath: / () (:goodfiles:)
        call /:verbosity:/ [directory scan for ':*:gooddir::*:goodwildcard:' --> ':*:dospath:' --> :*:goodfiles:\n]
    }
    alius
    {
        call /:verbosity:/ [mailtrainer: scan dir: find :*:gooddir: -type f -name ':*:goodwildcard:' -print]
        syscall /find :*:gooddir: -type f -name ':*:goodwildcard:' -print/ () (:goodfiles:)
        call /:verbosity:/ [directory scan for ':*:gooddir::*:goodwildcard:' --> :*:goodfiles:\n]
    }
    # output /goodfiles:  ':*:goodfiles:'\n/
    trap /.*/ (:reason:)
    {
        output /:*:reason:/
        output /Unable to process your gooddir at :*:gooddir: \n/
        alter (:report:) /:*:report: Unable to process your gooddir at :*:gooddir: \n/
        goto /:error_exit:/
    }
}

#################################################################
#
#     If --random, then we create the randomized interleaved list.
#     The list is the full filenames of the spam and good files,
#     each line is prefixed by S for Spam and G for Good

isolate (:randfiles:) //
{
    match [:single_file_mode:] <absent> /SET/

    # match [:random:] /SET/   <-- [i_a] always generate the S/G filelist; but 
    #                              only shuffle when random flag is set; code 
    #                              reduction / removed one duped section.

    call /:verbosity:/ [Generating the shuffle list for training\n]

    #  put the full filename for the spam files first
    match [:spamfiles:] //
    {
        match [:spamfiles:] <fromend> /[[:graph:]]+/ (:f:)
        # make sure filepath includes spamdir/gooddir:
        {
            match <absent> [:f:] /:*:spamdir:/
            alter (:f:) /:*:spamdir::*:f:/
        }
        alter (:randfiles:) /:*:randfiles:S :*:f:\n/
        liaf
    }
    output /\n Full set of SPAM files, after complete-pathing: \n:*:spamfiles:\n/
    
    # and the full filename of the good files next
    match [:goodfiles:] //
    {
        match [:goodfiles:] <fromend>  /[[:graph:]]+/ (:f:)
        # make sure filepath includes spamdir/gooddir:
        {
            match <absent> [:f:] /:*:gooddir:/
            alter (:f:) /:*:gooddir::*:f:/
        }
        alter (:randfiles:) /:*:randfiles:G :*:f:\n/
        liaf
    }
    output /\n Full set of GOOD files, after complete-pathing: \n:*:goodfiles:\n/
}
#
# shuffle the file set when we want randomized training:
#
{
    match [:single_file_mode:] <absent> /SET/
    match [:random:] /SET/
    match [:trainer_randomizer_command:] /./
    
    call /:verbosity:/ [Randomizing the shuffle list\n]

    # output / Full set of files, before sort-randomization: \n:*:randfiles:\n/
    
    # now randomize the files.  NOTE that this requires a shuffler
    # command somewhere.
    syscall (:*:randfiles:) (:randfiles:) /:*:trainer_randomizer_command:/
    
    # output /\n Full set of files, after randomize: \n:*:randfiles:\n/
}
    

#################################################################
#
#          Create spam.css and nonspam.css if they don't exist.
#
#  (OLD HACK: just learn a newline into each one)
#
{
    # only create the new CSS files when they don't exist yet:
    # if we can READ from them, they exist
    # (input [] is faster than syscall-based exist checks)
    input (:bogus_buf:) [:*:goodcss: 0 128]
    trap //

    call /:verbosity:/ [Creating a (yet empty) GOOD CSS database file ':*:goodcss:'\n]

    # [i_a]
    #
    # This is a clear spot for the use of the new 'csscreate' command!
    #csscreate <:*:clf:> /:*:lcr:/ (:*:goodcss:)
    learn [:_nl:] <:*:clf:> /./ (:*:goodcss:)
}
{
    input (:bogus_buf:) [:*:spamcss: 0 128]
    trap //

    call /:verbosity:/ [Creating a (yet empty) SPAM CSS database file ':*:spamcss:'\n]

    # [i_a]
    #
    # This is a clear spot for the use of the new 'csscreate' command!
    #csscreate <:*:clf:> /:*:lcr:/ (:*:spamcss:)
    learn [:_nl:] <:*:clf:> /./ (:*:spamcss:)
}


####################################################################
#
#      Top of the "entire directory" loop
:directory_loop_top:
#
###################################################################
{
    {
        eval /:@: :*:repeat: > :*:throughall: :/
        alter (:report:) /:*:report: \n\n Running all files\n/
        output /\n  Running all files\n/
    }
    alius
    {
        alter (:report:) /:*:report:\n\nFinished :*:repeat: passes \n/
        output /\n  Finished :*:repeat: passes.\n/
        goto /:good_exit:/
    }
}
########################################################################
#
#    Set up training lists for this pass.  We'll be chopping them up
#    presently.
#
#   the spam training list for this pass:
isolate (:stl:) /:*:spamfiles:/
#
#   the good training list for this pass:
isolate (:gtl:) /:*:goodfiles:/
#
#   the random training list for this pass:
isolate (:rtl:) /:*:randfiles:/
#

{
    match <absent> [:worst:] /no/
    output /\nTake a break.  This will require some time to finish. \n\n/
    {
        match [:worst:] /SET/   #  if no count set, default is 10
        alter (:worst:) /10/
    }
    goto /:worst_training:/
}

###################################################################
#    the top of the one-file-pair loop
###################################################################3
:one_file_pair_top:


call /:verbosity:/ [\n\
DEBUG: stl =':*:stl:'\n\
DEBUG: spamfiles = ':*:spamfiles:'\n\
DEBUG: gtl =':*:gtl:'\n\
DEBUG: goodfiles = ':*:goodfiles:'\n\
DEBUG: rtl =':*:rtl:'\n\
DEBUG: randfiles = ':*:randfiles:'\n\
DEBUG: spam = ':*:spam:'\n\
DEBUG: good = ':*:good:'\n\
DEBUG: spamdir = ':*:spamdir:'\n\
DEBUG: gooddir = ':*:gooddir:'\n\
DEBUG: spamwildcard = ':*:spamwildcard:'\n\
DEBUG: goodwildcard = ':*:goodwildcard:'\n]


##############################################################
#   Are we in "alternate one each" mode, or random shuffled mode?
#   Or are we in single-input mode?
#
{
    {
        match [:single_file_mode:] /SET/
        {
            match [:ftype:] /G/
            output /\nGood /

            #    output / M_TEXT: :*:m_text:\n/
            call /:test_train_good:/
        }
        alius
        {
            output /\nSpam /
            #    output / M_TEXT: :*:m_text:\n/
            call /:test_train_spam:/
        }
    }
    alius	
    {
        match [:random:] /SET/

        #   get a filename
        #   Remember that random-mode filenames are full-length already.
        call /:clip_filename:/ [:rtl:] (:lfilename:)
        match [:lfilename:] /(.) (.*)/ (:: :ftype: :filename:)
        #  Don't run it if it's in the "validate" set
        match <absent> [:filename:] /:*:validate:/
        {
            match [:ftype:] /G/
            output /\nGood :*:filename: /
            {
                #   Maybe it's a qualified name, maybe it's not
                input [:*:filename: 0 :*:decision_length:]

                call /:mail_preprocess:/ [:_dw:] (:m_text:)
                #    output / M_TEXT: :*:m_text:\n/
                call /:test_train_good:/
            }

		trap /.*/ (:reason:)
		{
			output / :*:reason:/
			output /Unable to process the GOOD file ':*:filename:'\n/
			alter (:report:) /:*:report: Unable to process the GOOD file ':*:filename:'\n/
			alter (:_dw:) /:*:_nl:/
		}
        }
        alius
        {
            match [:ftype:] /S/
            output /\nSpam :*:filename: /
            {
                #   Maybe it's a qualified name, maybe it's not
                input [:*:filename: 0 :*:decision_length:]

                call /:mail_preprocess:/ [:_dw:] (:m_text:)
                #    output / M_TEXT: :*:m_text:\n/
                call /:test_train_spam:/
            }

		trap /.*/ (:reason:)
		{
			output / :*:reason:/
			output /Unable to process the SPAM file ':*:filename:'\n/
			alter (:report:) /:*:report: Unable to process the SPAM file ':*:filename:'\n/
			alter (:_dw:) /:*:_nl:/
		}
        }
    }
    alius
    {
        match <absent> [:random:] /SET/
        #
        # No, we are in alternate mode.  Do 1 good, then 1 spam file.
        #
        # Get the first good file.  Note that if no files left, the match
        # just falls through and we don't do anything with this.
        #
        {
            call /:clip_filename:/ [:gtl:] (:filename:)
            match [:filename:] /./
            #  check - is this file in the validate set ?  If no, proceed.
            match <absent> [:filename:] /:*:validate:/
            output /\nGood file :*:filename: /
            {
                #   Maybe it's a qualified name, maybe it's not
                input [:*:filename: 0 :*:decision_length:]

                call /:mail_preprocess:/ [:_dw:] (:m_text:)
                #    output / M_TEXT: :*:m_text:\n/
                call /:test_train_good:/
            }

		trap /.*/ (:reason:)
		{
			output / :*:reason:/
			output /Unable to process the GOOD file ':*:filename:'\n/
			alter (:report:) /:*:report: Unable to process the GOOD file ':*:filename:'\n/
			alter (:_dw:) /:*:_nl:/
		}
        }
        #
        # ditto for the first spam file.  Again, if the match fails, there
        # were no filenames left, so we just fall through.
        #
        {
            call /:clip_filename:/ [:stl:] (:filename:)
            match [:filename:] /./
            #  check - is this file in the validate set ?  If no, proceed.
            match <absent> [:filename:] /:*:validate:/
            output /\nSpam file :*:filename: /
            {
                #   maybe it's a qualified name, maybe it's not
                input [:*:filename: 0 :*:decision_length:]

                call /:mail_preprocess:/ [:_dw:] (:m_text:)
                #    output / M_TEXT: :*:m_text:\n/
                call /:test_train_spam:/
            }

		trap /.*/ (:reason:)
		{
			output / :*:reason:/
			output /Unable to process the SPAM file ':*:filename:'\n/
			alter (:report:) /:*:report: Unable to process the SPAM file ':*:filename:'\n/
			alter (:_dw:) /:*:_nl:/
		}
        }
    }
}

#       Do we exit, or go 'round again?
#
#    First check on a long-enough streak of good classifications.
{
    eval /:@: :*:cleanrun: > :*:streak: :/
    alter (:report:) /:*:report: \n Got a clean run of :*:cleanrun: \n  Exiting now. \n\n/
    output /\nExcellent!  Got a streak of :*:cleanrun: without errors.\n/
    output /Finishing up.\n/
    goto /:good_exit:/
}

#
#          did we get through all of the file names? When not, loop!
#
{               
    #  Most common case - neither fileset is empty
    {
        match [:random:] /SET/
        {
            match [:rtl:] /./
            goto /:one_file_pair_top:/
        }
    }
    alius
    {
        # directory or single file mode:

        match [:gtl:]  /./
        match [:stl:]  /./
        goto /:one_file_pair_top:/
    }
}

#
# If a fileset is empty, and reload is set, we reload that fileset
# independently and immediately
#
{
    match [:reload:] /SET/

    # [i_a]
    # Ah! now I see what was being attempted here: assume short good list and long bad list:
    # to ensure 1 against 1 training, the 'good' list is rotated (repeated) before
    # the bad list is completely done, so such a repeat is counted as a 0.5 cycle, so
    # the total number of cycles of good+bad end up at the 'repeat' limit. This, of course,
    # means in the assumed situation described the total number of 'good' runs is more than
    # the number of 'bad' retrains as the 'good' list was the shorter one. Hm...
    #
    # ...hm. Now assume the G list was shorter than B, so it's actually empty once we arrive
    # here (thanks to :clip_filename: all the time up there), and we have an B sized
    # spam list: the old code would match(&break) before adding the G '0.5' to :throughall:,
    # resulting in the :throughall: repeat counter only being incremented by A HALF each
    # time, which would produce TWICE the number of repeats compared to the user --repeat
    # option in the situation where one start out with an EMPTY G (good) list to begin with.
    # The NEW code below remedies this, by ensuring the full +1 is added to the counter
    # when mailtrainer got fed only a Good or Spam list.
    #
    # ... And then there's the scenario when you have exactly as much G as B: in case of
    # --reload, the old code would ONLY update :gtl: and then, during the next round up
    # there, update :stl:, resulting in a learn pattern of G1 G2 S1 up there instead of
    # a repeat of G1 S1 G2 S2.
    # The NEW CODE remedies this as well.
    #
    # Regarding --repeat: the code now (still) counts 'repeat cycles' based on the
    # shortest (non-empty) filename set of G and S:
    {
        isolate (:throughall_add:) /0/

        {
            match [:gtl:] <absent> /./
            eval (:throughall_add:) /:@: :*:throughall_add: + 1 :/
            
            isolate (:gtl:) /:*:goodfiles:/
            alter (:report:) /:*:report: \n\n Repeating good files\n/
            output /\nRepeating good files\n/
        }
        {
            match [:stl:] <absent> /./
            eval (:throughall_add:) /:@: :*:throughall_add: + 1 :/
            
            isolate (:stl:) /:*:spamfiles:/
            alter (:report:) /:*:report: \n\n Repeating spam files\n/
            output /\nRepeating spam files\n/
        }
        {
            match [:rtl:] <absent> /./
            eval (:throughall_add:) /:@: :*:throughall_add: + 1 :/
            
            isolate (:rtl:) /:*:randfiles:/
            alter (:report:) /:*:report: \n\n Repeating RANDOM files\n/
            output /\nRepeating RANDOM files\n/
        }
        
        {
            eval /:@: :*:throughall_add: >= 1 :/

            eval (:throughall:) /:@: :*:throughall: + 1 :/
            eval /:@: :*:throughall: <= :*:repeat: :/

            goto /:one_file_pair_top:/
        }
        alius
        {
            goto /:good_exit:/
        }
    }
}

# [i_a]
# and then, in case we didn't select the auto-'reload' option, we loop as is.
#
# CAVEAT EMPTOR: this means the lists are BOTH reloaded, so the shortest list
# of the both of them determines how many are tested/trained: say you have a list
# of G good ones and B bad ones and G < B, than this code will NEVER train
# the bad ones at positions [G+1 .. B] in the 'bad' list as we would have
# arrived here when G items of both lists have been trained: 'good' list is empty
# then, no 'auto-reload' as above, so it's straight to the bitbucket with those
# remaining bad ones.
#
# I don't think you'd want that, but then I guess the above behaviour is a side-effect
# of this 'smart' code assuming either fully balanced G/B inputs or single-sided
# G or B inputs (single-sided = only passing G good ones for training OR B bad
# ones, but NOT both at the same time. (The 'balancing act' would then be based
# on the (hopefully longer) lists of good and bad ones in the cache directories.
#
# Anyway, this bit here is useful for '--random'ized training lists as well, as
# then all to-be-trained files are plonked into a single set: :rtl:.
#

#
#		yep; through all the filenames.  Increment the :throughall: counter
#       and maybe go through it all again.
#
{
    eval (:throughall:) /:@: :*:throughall: + 1 :/
    goto /:directory_loop_top:/
}

#
#		All done now with repeats through the loop.
#       Now we update the report and we're done.
#
alter (:report:) /:*:report: \n\n Finished with :*:repeat: passes.\n\n  Training complete!\n\n\n/

goto /:good_exit:/






#############################################################
#        Get a filename off the front of a list, whacking the list.
#############################################################
#
:clip_filename: (:namelist:)
{
    {
        isolate (:filename:) //     # start with an empty filename
        match [:*:namelist:] /([[:print:]]+)\n/ (:wholeline: :filename:)
        match [:filename:] /./      # assure filename is non-NULL
        isolate (:filename:)
        alter (:wholeline:) //      # surgically delete the found filename
        # output /Got the filename :*:filename:/
    }
    alius
    {
        alter (:filename:) //
    }
}
return /:*:filename:/


##############################################################
#
#     The actual code that does a CLASSIFY and maybe a LEARN
#
#     This assumes the input text is in :m_text:
#
##############################################################
#

:test_train_good:
{
    #   Classify the text
    call /:get_pr:/ [:m_text:]
    {
        match [:force:] /SET/
        goto /:force_train_good:/
    }
    alius
    {
        # [i_a] we are not classifying here to 'classify' but to check against the 'thick threshold' we
        # want to train against.
        # Yes, this means a successful 'training' MAY lead to trained files STILL being re-classified as
        # DONT KNOW when you check them lateron using a separate reaver run or other true classify operation.
        # To make sure this would be RARE case, mailtrainer now has code at the top to ensure
        # our 'thick threshold' is never LESS THAN any of the two classify thresholds: good or bad.
        
        eval /:@: :*:pr: < :*:thick_threshold: : /
:force_train_good:
        {
            {
                eval /:@: :*:pr: > 0 :/
                output / -- (:*:pr:) train /
            }
            alius
            {
                output / ER (:*:pr:) train /
            }
        }
        alter (:report:) /:*:report: Training GOOD on :*:filename: (pR was :*:pr:) \n /

        learn [:m_text:] <:*:clf:> /:*:lcr:/  \
                (:*:goodcss:)

        alter (:cleanrun:) /0/
        #   REclassify to see if we're now "good"; if not, refute!
        call /:get_pr:/ [:m_text:]
        {
            eval /:@: :*:pr: < :*:thick_threshold: : /
            match [:do_refute_training:] /SET/
            {
                match [:clf:] <absent nocase> /fscm/  # [i_a] HyperSpace supports refute these days, it seems
                output /& refute /
                alter (:report:) /:*:report: & refute/

                learn [:m_text:] <:*:clf: refute> /:*:lcr:/  \
                      (:*:spamcss:)
            }
            alius
            {
                # [i_a] given the --repeat parameter, which loops through the complete mail directories,
                #       this will give you a maximum of repeat * 2 'learn' operations per email in worst-case.
                output /& repeat /
                alter (:report:) /:*:report: & repeat/
                learn [:m_text:] <:*:clf:> /:*:lcr:/  \
                      (:*:goodcss:)
            }
        }
        {
            match [:collapse:] <absent> /SET/
            output /\n/
        }
    }
    alius
    {
        eval (:cleanrun:) /:@: :*:cleanrun: + 1:/
    }
}
return


##############################################################
#
#     The actual code that does a CLASSIFY and maybe a LEARN
#
#     This assumes the input text is in :m_text:
#
##############################################################
#

:test_train_spam:
{
    #   Classify the text
    call /:get_pr:/ [:m_text:]
    {
        match [:force:] /SET/
        goto /:force_train_spam:/
    }
    alius
    {
        # [i_a] we are not classifying here to 'classify' but to check against the 'thick threshold' we
        # want to train against.
        # Yes, this means a successful 'training' MAY lead to trained files STILL being re-classified as
        # DONT KNOW when you check them lateron using a separate reaver run or other true classify operation.
        # To make sure this would be RARE case, mailtrainer now has code at the top to ensure
        # our 'thick threshold' is never LESS THAN any of the two classify thresholds: good or bad.

        eval /:@: :*:pr: > (0 - :*:thick_threshold:) : /
:force_train_spam:
        {
            {
                eval /:@: :*:pr: < 0 :/
                output / -- (:*:pr:) train /
            }
            alius
            {
                output / ER (:*:pr:) train /
            }
        }
        alter (:report:) /:*:report: Training SPAM on :*:filename: (pR was :*:pr:) \n /

        learn [:m_text:] <:*:clf:> /:*:lcr:/  \
                (:*:spamcss:)

        alter (:cleanrun:) /0/
        #   REclassify to see if we're now "good"; if not, refute!
        call /:get_pr:/ [:m_text:]
        {
            eval /:@: :*:pr: > (0 - :*:thick_threshold:) : /
            match [:do_refute_training:] /SET/
            {
                match [:clf:] <absent nocase> /fscm/  # [i_a] HyperSpace supports refute these days, it seems
                output /& refute /
                alter (:report:) /:*:report: & refute/
                learn [:m_text:] <:*:clf: refute> /:*:lcr:/  \
                        (:*:goodcss:)
            }
            alius
            {
                # [i_a] given the --repeat parameter, which loops through the complete mail directories,
                #       this will give you a maximum of repeat * 2 'learn' operations per email in worst-case.
                output /& repeat /
                alter (:report:) /:*:report: & repeat/
                learn [:m_text:] <:*:clf:> /:*:lcr:/  \
                        (:*:spamcss:)
            }
        }
        {
            match [:collapse:] /SET/ <absent>
            output /\n/
        }
    }
    alius
    {
        eval (:cleanrun:) /:@: :*:cleanrun: + 1:/
    }
}
return


###################################################
:error_exit:
{
    output /\n\n Something went very wrong.  You might want to debug.\n\n/
}
return /1/

#####################################################
:good_exit:
{
    # did the user ask for a validation pattern?
    #   ( this is the never-match pattern )
    match [:validate:] <absent literal> /[^\x00-\xFF]/

    isolate (:spamtested:) /0/
    isolate (:spampassed:) /0/
    isolate (:goodtested:) /0/
    isolate (:goodpassed:) /0/
    isolate (:tottested:)  /0/
    isolate (:totpassed:)  /0/
    isolate (:overall:)    /0/
    isolate (:stl:) /:*:spamfiles:/
    isolate (:gtl:) /:*:goodfiles:/
    output /\n   Starting validation run, pattern ':*:validate:'\n/
    {
        call /:clip_filename:/ [:gtl:] (:filename:)
        match [:filename:] /./
        {
            #  check - is this file in the validate set?  If YES, proceed
            match [:filename:] /:*:validate:/
            input [:*:filename: 0 :*:decision_length:]
            
            call /:mail_preprocess:/ [:_dw:] (:m_text:)
            call /:get_pr:/ [:m_text:]
            #  Keep track of our statistics
            {
                eval (:goodtested:) /:@: :*:goodtested: + 1 :/
                eval (:goodpassed:) /:@: :*:goodpassed: + ( :*:pr: > 0 ) :/
            }
            output /\n:*:filename: G (:*:goodpassed:) :*:pr:\n/
        }
        liaf
    }
    {
        call /:clip_filename:/ [:stl:] (:filename:)
        match [:filename:] /./
        {
            #  check - is this file in the validate set ?  If YES, proceed
            match [:filename:] /:*:validate:/
            input [:*:filename: 0 :*:decision_length:]

            call /:mail_preprocess:/ [:_dw:] (:m_text:)
            call /:get_pr:/ [:m_text:]
            #  Keep track of our statistics
            {
                eval (:spamtested:) /:@: :*:spamtested: + 1 :/
                eval (:spampassed:) /:@: :*:spampassed: + ( :*:pr: < 0 ) :/  # [i_a]
            }
            output /\n:*:filename: S (:*:spampassed:) :*:pr:\n/
        }
        liaf
    }
    output /\nSummary of validation on :*:validate::\n/
    alter (:report:) /:*:report: \n\n Summary of validation:\n/
    eval (:overall:) /:@: 100 * :*:goodpassed: \/ :*:goodtested: :/
    output /Good files: :*:goodtested:  correct: :*:goodpassed:  accuracy: :*:overall:\n/
    alter (:report:)  /:*:report:\nGood files: :*:goodtested:  correct: :*:goodpassed:  accuracy: :*:overall:/
    {
        match [:rfile:] /./
        output <append> [:*:rfile:] /Good files: :*:goodtested:  correct: :*:goodpassed:  accuracy: :*:overall:\n/
    }
    eval (:overall:) /:@: 100 * :*:spampassed: \/ :*:spamtested: :/
    output /Spam files: :*:spamtested:  correct: :*:spampassed:  accuracy: :*:overall:\n/
    alter (:report:) /:*:report:\nSpam files: :*:spamtested:  correct: :*:spampassed:  accuracy: :*:overall:/
    {
        match [:rfile:] /./
        output <append> [:*:rfile:] /Spam files: :*:spamtested:  correct: :*:spampassed:  accuracy: :*:overall:\n/
    }
    eval (:tottested:) /:@: :*:goodtested: + :*:spamtested: : /
    eval (:totpassed:) /:@: :*:goodpassed: + :*:spampassed: : /
    eval (:overall:) /:@: 100 * (:*:totpassed: \/ :*:tottested: ) :/
    output /Overall:   :*:tottested:  correct: :*:totpassed:  accuracy: :*:overall:\n/
    alter (:report:) /:*:report:\nOverall:    :*:tottested:  correct: :*:totpassed:  accuracy: :*:overall:\n/
    {
        match [:rfile:] /./
        output <append> [:*:rfile:] /Overall:    :*:tottested:  correct: :*:totpassed:  accuracy: :*:overall:\n/
    }
}

#  output /:*:report:/
return /0/



###########################################################
#
#    Worst training - similar to an SVM, but without the
#    grace and beauty.  We train only the minimal set of
#    features that gain us the maximal response.
#
#    Algorithm
#       1 - train a *single* example into each class.
#       2 - evaluate all other examples.
#       3 - pick the "worst error(s)" in each class
#       4 - Are the worst errors close enough?  If so, stop
#       5 - train those worst errors
#       6 - go to 2

:worst_training:

#####  Step 1 - train a single example in each class, to get "off center"
#
# [i_a] This code assumes that a pR = 0.0 (or VERY close to zero) does not
# happen once the CSS databases have at least one message trained into them.
# Generally, this is a 'good enough' assumption.
#
{
    call /:clip_filename:/ [:gtl:] (:filename:)
    input [:*:filename: 0 :*:decision_length:]

    call /:mail_preprocess:/ [:_dw:] (:m_text:)
    call /:get_pr:/ [:m_text:]
    {		
        # if this is a ZERO :pr:, train something
        eval /:@: :*:pr: = 0 :/
        output /\n Learning :*:filename: as initial good mail seed.\n/
        learn [:m_text:] <:*:clf:> /:*:lcr:/  \
                (:*:goodcss:)
    }
}
{
    call /:clip_filename:/ [:stl:] (:filename:)
    input [:*:filename: 0 :*:decision_length:]

    call /:mail_preprocess:/ [:_dw:] (:m_text:)
    call /:get_pr:/ [:m_text:]
    {
        # if this is a ZERO :pr:, train something
        eval /:@: :*:pr: = 0 :/
        output /\n Learning :*:filename: as initial spam mail seed.\n/
        learn [:m_text:] <:*:clf:> /:*:lcr:/  \
               (:*:spamcss:)
    }
}

output /\n/  # make a little space before the "sputter" display.

#####  Step 2 - Test each of the files, and keep track of the :worst: worst
#####           error cases.  To make our life easy, we just call out to
#####           the "sort" utility via syscall.
#####
#####           Note that there's no need to do this alternating, because
#####           sort()ing will fix order anyway.

:worst_loop:

#   load up the good files and spam files
isolate (:gtl:) /:*:goodfiles:/
isolate (:stl:) /:*:spamfiles:/


{
    alter (:worst_results:) //
    {
        call /:clip_filename:/ [:stl:] (:filename:)
        match [:filename:] /./
        {
            #  check - is this file in the validate set?  If no, proceed.
            match <absent> [:filename:] /:*:validate:/
            input [:*:filename: 0 :*:decision_length:]

            call /:mail_preprocess:/ [:_dw:] (:m_text:)
            call /:get_pr:/ [:m_text:]
            eval (:pr:) /:@: (0 - :*:pr:) f 10.4:/
            alter (:worst_results:) \
                    /:*:worst_results:\n:*:pr: S :*:filename:/
            output /\n:*:pr: S :*:filename:\n/
        }
        liaf
    }
    {
        call /:clip_filename:/ [:gtl:] (:filename:)
        match [:filename:] /./
        {
            #  check - is this file in the validate set?  If no, proceed.
            match <absent> [:filename:] /:*:validate:/
            input [:*:filename: 0 :*:decision_length:]

            call /:mail_preprocess:/ [:_dw:] (:m_text:)
            call /:get_pr:/ [:m_text:]
            eval (:pr:) /:@: :*:pr: f 10.4 :/
            alter (:worst_results:)  \
                    /:*:worst_results:\n:*:pr: G :*:filename:/
            output /\n:*:pr: G :*:filename:\n/
        }
        liaf
    }
}

#####  Step 3 --- Sort the worst results, to get the N worst errors
#####             Note that this is a "numeric" sort, and minimum values
#####             are "worst" in either direction.

{
    syscall /sort -n / (:*:worst_results:) (:worst_results:)
    match /([^\n]+\n){1,:*:worst:}/ [:worst_results:] \
            (:worst_retrains:)
    output /\n\n   Worst Training Candidates:\n\n/
    output /:*:worst_retrains:\n/
}

#####  Step 4 ---  Is the worst of the worst good enough?
#####              Note that we test here, before we retrain anything.
#####  (note the .00001 adder - that's to prevent getting exactly stuck)

{
    match (:pr:) [:worst_retrains:] /[[:graph:]]+/
    eval /:@: ( :*:pr: + .00001 ) > :*:thick_threshold: :/
    output /\nLooks good... exiting!\n/
    goto /:good_exit:/
}

#####  Step 5 ---  Train only those worst errors
#####              Easily done, as the full filename is "coded" into
#####              the report, as well as what to train it as.

{
    match (:nextline: :pr: :type: :filename:) [:worst_retrains:] \
         /([[:graph:]]+) +([[:graph:]]+) +([[:graph:]]+)\n/
    input [:*:filename: 0 :*:decision_length:]

    call /:mail_preprocess:/ [:_dw:] (:m_text:)
    {
        {
            match [:type:] /G/
            output /\nConsidering :*:filename: as good\n/
            call /:test_train_good:/
        }
        alius
        {
            output /\nConsidering :*:filename: as spam\n/
            call /:test_train_spam:/
        }
    }
    alter (:nextline:) //
    liaf
}

output /\n/

######   Step 6 - otherwise, go to 2
######

goto /:worst_loop:/







######################################################3
trap (:broken_program_message:) /.*/
{
    output /:*:_nl: Aw, crud.  mailtrainer.crm broke.  Here's the error::*:_nl:/
    output /:*:broken_program_message::*:_nl:/
    output [stderr] /:*:_nl:ERROR: mailtrainer.crm broke.  Here's the error: :*:_nl:/
    output [stderr] /ERROR::*:broken_program_message::*:_nl:/
}
isolate <default> (:program_fault_exit_code:) /66/
exit /:*:program_fault_exit_code:/




######################################################################3
#
#              Library insertions start here.
#
insert maillib.crm


